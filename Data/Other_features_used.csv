,Paper,year,category,Definition of Cyber-Bullyning,Type of Cyber-bullying,Dataset,Dataset positive sample,Dataset negative sample,Data Downlaoded,Data Collection process,Oversampleing pst instances,Preprocessing,Text Feature,Psycological features,User info features,Sentiment features,WE,Other features,ML model,Deel Learning model,Innovative model,baselines,Test set,Test positive ex.,Test negative ex.,Accuracy,Precision,Recall,AUC,F1,venue,Comments
1,Detection of harassment on web 2.0,2009,Cyber-Bullyiing detetction,communication in which a user intentionally annoys one or more others in a web community,personal insult harassment in which a user systematically deprecates the contributions of another user,"kongregate (4,802)
slashdot (4,303)
myspace (1,946)","kongregate (42)
slashdot (60)
myspace (65)","kongregate (4760)
slashdot (4243)
myspace (1881)",0.0,used from CAW comprtion,1,1,"TF-IDF
ngrams",0,0,1,0,contextual features,0,0,0,0,0,0,0,0,"kongregate (0.35)
slashdot (0.32)
myspace (0.41)","kongregate (0.59)
slashdot (0.27)
myspace (0.25)",0,"kongregate (0.44)
slashdot (0.29)
myspace (0.313)",the Content Analysis in the WEB (CAW 2.0),0
8,Using Machine Learning to Detect Cyberbullying,2012,Cyber-Bullyiing detetction,"cyberbullying as willful and repeated harm inflicted through the medium of electronic text
","flooding, masquerade, flaming,
trolling, harassment, cyberstalking, denigration, outing, and exclusion.","Forspring.me (13,652 post)",792 (5.8%),"12,860 (94.2%)",1.0,"Crawled and labeled by AMT with 3 workers labelled each post
they don't mention the inter-agreement score",0,0,"1-per post: No. bad words, pcntg of bad words, No.words, severity of bad word
2-BOW",0,0,0,0,user anonymity,"Decision trees, Rule based, KNN, SVM (sequential minimal optimization)",0,0,0,2696,195 (7.2%),2501(92.8%),0,0,"87.50% (reported)
73.14% (me calculated avg  of  all 10 user files)",0,0,Ursinus College,"1- The study reports that rule based model gave the best results but actually when I calculated the avg, I found it is the KNN. May be I calculate something in the wrong way
2- The anonmity featrue made the results worse
3- they use BOW not as a feature t"
16,You too?! mixed-initiative lda story matching to help teens in distress,2012,theme related Cyber-Bullyiing detetction,traditional bullying definition from the perspective of teenages,0,MTC teenage srtories (5500),0,0,0.0,0,0,0,TF-IDF,0,0,0,0,sociolinguistic assignmnet of thems,LDA,0,0,0,0,0,0,0,0,0,0,0,International AAAI Conference on Weblogs and Social Media,they use Kappa values to measure assigment of teenages discussion themes in bullying stories told be distressed teenages
25,Expert knowledge for automatic detection of bullies in social networks,2013,Cyber-Bullyiing detetction,"Cyberbullying is defined as an aggressive, intentional
act carried out by a group or individual, using electronic forms of contact repeatedly
and over time against a victim who cannot easily defend him or herself",assigning bullying score to people,"youtube(54,050 comments from 3,603 usesrs)",12% of users are bullies,88%,1.0,"2 graduate studentns labeled the users as bullies or not 
with inter agreement Kappa of 0.78",0,0,"no profane words,
length of comment,
misspellings and short words,
comments targeted to someone
tf-idf",0,"hidden identities,
age of user,
period of membership,
no uploads,
no subscrptions,
no comments",no emotion icons,0,"A) Experts: a panel of 12 experts in the area of cyberbullying was asked to answer questions about the features presented in Table 1. For each feature they indicated 1) the
likelihood that a bully user belongs to a certain category relevant for that feature and
2) the importance of that feature. The likelihood was indicated on four-point scale
‘Unlikely’, ‘Less likely’, ‘Likely’ and ‘Very likely’ corresponding to values 0.125,0.375, 0.625 and 0.875 respectively
B)MCES decision making systems
","NB, SVM, C4.5, MCES",0,0,SVM (text features),0,0,0,MCES (0.76),0,0,0,0,anadian Conference on Artificial Intelligence,"2- We demonstrated that the expert system outperforms the machine
learning models and the hybrid approach results in a further but marginal improvement in prediction performance
1- compare three types of automatic detection: an expert system, supervised machine learning models, and a hybrid type combining the two."
29,Experts and Machines against Bullies: A Hybrid Approach to Detect Cyberbullies ,2014,Cyber-Bullyiing detetction,"Cyberbullying is defined as an aggressive, intentional
act carried out by a group or individual, using electronic forms of contact repeatedly
and over time against a victim who cannot easily defend him or herself",assigning bullying score to people,"youtube(54,050 comments from 3,603 usesrs)",12% of users are bullies,88%,1.0,"2 graduate studentns labeled the users as bullies or not 
with inter agreement Kappa of 0.78",0,0,"no profane words,
length of comment,
misspellings and short words,
comments targeted to someone
tf-idf",0,"hidden identities,
age of user,
period of membership,
no uploads,
no subscrptions,
no comments",no emotion icons,0,"A) Experts: a panel of 12 experts in the area of cyberbullying was asked to answer questions about the features presented in Table 1. For each feature they indicated 1) the
likelihood that a bully user belongs to a certain category relevant for that feature and
2) the importance of that feature. The likelihood was indicated on four-point scale
‘Unlikely’, ‘Less likely’, ‘Likely’ and ‘Very likely’ corresponding to values 0.125,0.375, 0.625 and 0.875 respectively
B)MCES decision making systems
","NB, SVM, C4.5, MCES",0,0,SVM (text features),0,0,0,MCES (0.76),0,0,0,0,anadian Conference on Artificial Intelligence,"2- We demonstrated that the expert system outperforms the machine
learning models and the hybrid approach results in a further but marginal improvement in prediction performance
1- compare three types of automatic detection: an expert system, supervised machine learning models, and a hybrid type combining the two."
30,Cyberbullying Detection using Time Series Modeling,2014,Cyber-Bullyiing detetction,"It is defined as a person tormenting, threatening,
harassing or embarrassing another person using the internet or
other technologies, like cell phones",online grooming,PJ (31 transcripts),0,0,0.0,"use dataset from 2010 Kontostathis et al.,",0,0,"tf-idf,
term frequency,
term occurrence,
binary term occurrence",0,0,0,0,"SVD,
Time series",linearSVM and Polynomial SVM,no,no,MLP,0,0,0,RMSE(0.117),0,0,0,0,IEEE International Conference on Data Mining Workshop 2014,"1-MLP is better than SVM
2- SVD is better feature representaion"
33,detecting online harassment in social networks,2014,online harassment,the process of sending messages over electronic media to casue psychological harm to a victim. If it persists then it is cyber bullying.,online harassment,"Twitter_general (5382)
Twitter_school (2793)
","Twitter_general (220 - 4%)
Twitter_school (194 - 7.4%)","Twitter_general (5162 - 96%)
Twitter_school (2599 - 92.6%)",0.0,Twitter API and annotated by 3 annotators. Twitter_school used school related keywords,0,"POS
noise (misspelling slang and abbreviations) removal
Twitter preprocessing",BOW,0,0,0,0,person identification - mark words or phrases that refer to a person using POS and usernames,NB,0,0,0,0,0,0,0,0.94,0.32,0,0.48,International Conference on Information Systems 2014,0
42,A DYNAMIC COGNITIVE SYSTEM FOR AUTOMATIC DETECTION AND PREVENTION OF CYBER-BULLYING ATTACKS,2015,Cyber-Bullyiing detetction,"is intentional and aggressive act accomplished over a period of time by 
an individual or a group of individuals through an electronic 
medium over feeble victim who cannot sheild themselves",0,0,0,0,0.0,0,0,stop words removal ,1,0,"user info
network info",0,0,image,0,0,0,0,0,0,0,0,0,0,0,0,ARPN journal of engineering and applied sciences,they use rule based system
44,Cyberbullying detection and classification using information retrieval algorithm,2015,Cyber-Bullyiing detetction,"an intensional aggressive act carried out by a group or i
ndividual using electronic forms of contact repeatedly and
 over time against a victim who cannot easilt defend themselves",0,"FormSpring.me (500)
MySpace (600)",0,0,0.0,CAW 2.0,0,remove stop words and unwanted characters,"BOW
NLP
POS",0,0,0,0,"levenshtein distance 
to detect the bullying 
words in the text",NB,0,0,0,0,0,0,"MySpace(0.91)
FormSpring (0.92)",0,0,0,"MySpace(0.0.89)
FormSpring (0.87)",International Conference on Advanced Research in Computer Science Engineering and Technology,0
46,A Framework for Cyberbullying Detection in Social Network,2015,Cyber-Bullyiing detetction,"is an online attack based on deliberately insulting, threatening, embarassing or 
harassing people on the internet. It also indicates the communication with the victim through 
the abusive texts and images via social media",abusive content,0,0,0,0.0,0,0,"removing stop words
tokenization
stemming
strip white spaces
spelling and grammer correction
",BOW,0,0,0,0,"image features using Loca
l binary pattern (LBP)",SVM,0,combining text and image features,0,0,0,0,0,0,0,0,0,International Journal of current engineering and technology,they proposed the idea but havenot applied it
47,"Hateful Symbols or Hateful People?
Predictive Features for Hate Speech Detection on Twitter",2016,Cyber-Bullyiing detetction,"they define hate speech as negating the privileages of white people listed in (McIntosh (2003))
They provide a list of 12 charcteristics that describe hate speech  and compared against each tweet to label them",hate speech: racism and sexism,"Twitter collected over 2 months
16,014 labelled","3,383 (21% - sexist sent by 612 users)
1,972 (12% - rascist sent by 9 users)","11,559 (72%)",1.0,"Crawled  from Twitter piblic API by using keywords like “MKR”, “asian drive”, “feminazi”,
“immigrant”, “nigger”, “sjw”, “WomenAgainstFeminism”,
“blameonenotall”, “islam terrorism”, “notallmen”,
“victimcard”, “victim card”, “arab terror”, “gamergate”,
“jsi",0,0,character n-gram,0,"1-gender
2-location
3-length of user's desc.",0,0,"1-most frquent words in racist anf sexist tweets.
2- avg and total length of tweets
",logistic regression,0,0,0,0,0,0,0,72.93,77.74,0,73.93,Association for Computational Linguistics 2016,"1- Feature engineering.
2-We find that using character n-grams of
lengths up to 4, along with gender as an additional
feature provides the best results.
3-location and length as features made the score worse."
50,Automatic detection of cyberbullying on social networks based on bullying features,2016,Cyber-Bullyiing detetction,0,0,Twitter (1762),685,1078,1.0,"tweets crwled from public twitter api using these words bullying, bullyied and bully.",0,0,Tfidf BOW,0,0,0,EBOW: bullying features word embeddings,LSA,SVM + EBOW,0,"concatenating BOW + LSA + woed embeddings for 
bullying extentded seed words.","BOW, LSA, semantic BOW, LDA ",5 folds,0,0,0,76.8,79.4,0,78,ICDCN ’16,innovaion in feaure representaion
53,Supervised machine learning for the detection of troll profiles in twitter social network: Application to a real case of cyberbullying,2016,troll profiles,"any harassment that occurs via the internet, cell phones or other devices. This type of bullying uses
this type of bullying uses communication technologies to intentionally harm others through hostile 
behaviour such as sending text message and posting ugly comments on the internet",0,Twitter (1900 - 19 twitter account),0,0,0.0,0,0,tokenizatoin,"ngrams
tf-idf",0,"language
position
time of publication",0,0,authorship,"RF
DT
KNN
SMO
NB",0,0,0,0,0,0,(SMO)0.68,0,0,(SMO) 0.96,0,Logic Journal of the IGPL,they detect troll profiles not bullying incidents
56,"Cyberbullying Detection with a Pronunciation
Based Convolutional Neural Network",2016,Cyber-Bullying detetction,"is an aggressive, intentional act conducted by either a group or an individual in 
cyberspace conducted by either a group or an individual in cyberspace 
using information and communication technologies",0,"Twitter (1313)
Formspringme (13000)","Twitter (39%)
Formspring (7%)","Twitter (61%)
Formspring (93%)",1.0,from other researchers,0,"removing usernames
hashtags
hyperlinks",0,0,0,0,1,Pronounciation conversion,0,CNN,0,"RF
SVM
DT",0,0,0,0,0.991,0.97,0.98,0.989,2016 15th IEEE International Conference on Machine Learning and Applications,0
58,"Cybercrime detection in online communications: The experimental
case of cyberbullying detection in the Twitter network",2016,Cyber-Bullying detetction,"0Cyberbullying behaviors are defined as aggressive behaviors
exhibited through electronic or digital media and intended to inflict
harm or discomfort to a victim",aggressive behaviour,Twitter (10007),Twitter (599),0,0.0,handl labbeled by 3 experts,oversampling the minority and under sample majority class,"lowercase
urls user mentions replaced with special characters
correcting misspelled words
remove white spaces","vulgar words
fisrt and second person pronouns
bullying acrynomes",neurotic features,"network features
user activity features
age
gender
",0,0,"activity features
specific social network cyberbullying features
measure features usefulness using cho-square test information gain and pearson correlation","SVM
NB
RF
KNN",0,0,0,0,0,0,0,SVM + information gain (0.994),SVM + information gain (0.890),SVM + information gain (0.500),SVM + information gain (0.943),journal Computers in Human Behavior,"We select three features selection algorithms, namely, c 2
test, information gain, and Pearson correlation, to determine the
most significant proposed features. The synthetic minority over-
sampling technique (SMOTE) approach and the weights
adjusting approach (cost-sensitive) are used to balance the
classes in the data set. Th"
61,Mean birds: Detecting aggression and bullying on twitter.,2017,Cyber-Bullyiing detetction,"Cyberbullying and
cyberaggression can take many forms and de_x005F_x005F_x005F_x005F_x005F_x001B_nitions however, the former typically denotes repeated and hostile behavior
performed by a group or an individual and the latter intentional
harm delivered via electronic means to a person or a ",Cyberbullying and Cyber aggressive,"Twitter(9,484)","1-base line with all tweets
2- hatespeech with hashtags related to hate speech",0,0.0,"data labelled using CF workers.
5 workers pr batch
agreement score 0.45",0,0,"avg no. hashtags used, emotionicons,uppercases and urls

",0,"no.posts, friends, 
followers","sentiment score
hate score",avg word embeddings scor,"network fetures like: avg power difference, influence score","J48, LADTree, LMT, NBTree, RF, Funcitonal tree",0,0,0,10%,0,0,0,89.9,91.7,0.907,0,Websci 2017,"1- they label users as bullies, agressors or not
2- the innovaion is in using different combinations of features"
64,"Automatic detection of cyberbullying in social
media text",2017,0,a content taht is published online by an individual and that is aggressive or hurtful against a victim,"threat
insult
exclusion
sexual talk
defense
encouragment to harassment","Askfm - Englsih (113698)
Askfm - Ducth (78387)",0,0,1.0,"data annotated by experts (linguists) with
 interannotator agreement score (Cohen kappa - Ducth) 
is 0.69 and (Fleiss kappa - English) is 0.59",cost-senstive,"POS
lemmatisation
","word n-grams
char n-gram
BOW
Term lists",0,0,1,0,Topic modelling (LDA nad LSI),SVM,0,0,0,0,0,0,0,"English (0.74)
Dutch (0.67)",English (0.56) Dutch (0.52),"AUCROC
English (0.77) Dutch (0.75)
",English (0.64) Dutch (0.58),PLOS ONE journal,they comapre the performance of different combinations of features and the performance to detect different types of cyberbullying
66,Automated cyberbullying detection using clustering appearance patterns,2017,grooming detection,0,grooming,"Perverted-justice (170019)
Twitter (476553560)","Perverted-justice (170019)
Twitter (476553560)",0,0.0,0,0,0,0,0,0,0,0,Kmeans,NB,0,0,0,0,0,0,0,0,0,0,0,0,"they use NB to classify the messgaes as bullying or not
then use Kmeans and categorize the bullying to its 8 subcategories"
70,Detecting Hate Speech on Twitter Using a Convolution-GRU Based Deep Neural Network,2018,Hate speech detetction,"we identify that hate speech
(1) targets individual or groups on the basis of their characteristics (targeting
characteristics); (2) demonstrates a clear intention to incite harm, or to promote
hatred; (3) may or may not use offensive or profane words.","hatespeech
refugees","Twitter (2,435)",414 (17%),2021 (83%),0.0,"annotated by liguistic researcher and 2 student researchers 
(agreement score not given)","filtering twitter api using keywords
 and hashtags in 3 batches",0,"(Unigrams,bigrams and trigrams )Tfidf
number of mentions, and hashtags4; 
number of characters, and words;",0,0,"sentiment polarity 
scores of the tweet",0,"1-Linguistic features like POS
2-Enhanced feature set",0,CNN + GRU,0,"SVM, CNN",0,0,0,0,0,0,0,0.92,Nature 2018,"it sets new benchmark by outperforming on 6 out of 7 datasets by between
1 and 13% in F1. We also extend the existing dataset collection on this
task by creating a new dataset covering different topics."
75,"Cyberbullying Detection on Social Network
Services",2018,0,"a use of information and communication technology to support malicious repetitive and hostile
behaviors against individuals or groups in order to harm other",Cyberbullying,Twitter ,0,0,0.0,0,0,"convert user mentions to special characters
remove urls puctuations and numbers
correct misspelling
segmantation
stemming
POS","vulgar words
person pronouns
BOW",0,"no user tweets
no words in seld introduction
image usage",1,0,"negative subjectivity
text readability
","KNN
SVM
DT",0,0,0,0,0,0,0,0,0,0,0,Twenty-Second Pacific Asia Conference on Information Systems,they dont report experiement results
79,A Socio-linguistic Model for Cyberbullying Detection,2018,Cyberbullying  and bullies,0,Cyberbullying,Twitter (1798),Twitter (27%),Twitter (73%),0.0,annotated by 3 annotators with Fleiss agreement score of 0.14,0,"remove stopwords 
remove numbers
remove nonenglish words
trimming repeated characters
","Ngram
Ngram++
seed++
latent linguistic",0,sociolinguistic,0,Glove ad Doc2vec,PSL,SVM,0,0,0,0,0,0,0,"cyberbullying(0.48)
bullies(0.61)","cyberbullying(0.70)
bullies(0.0.70)",0,"cyberbullying(0.56)
bullies(0.73)","IEEE/ACM ASONAM 2018, August 28-31, 2018","They use PLS and SVM to detect cyberbulling and bullies
"
82,A Simple Neural Network for Cyberbullying Detection,2019,Cyber-Bullyiing detetction,0,"harmful
hate speech
cyberbullying","Twitter (10,041)",850 (10%),9191 (90%),0.0,0,"the dataset was extended with artificially generated
training instances of harmful tweets. Two types of generated data were used:
1- Chunk shuffling.
2-Translation",0,chaacter n-gram,0,0,0,LASER ,"1-Morfeusz qualifiers
2-Vulgar/offensive words.",0,NN,0,0,0,0,0,0,0,0,0.837,0,Proceedings of the PolEval 2019 Workshop,0
84,XBully: Cyberbullying Detection within a Multi-Modal Context,2019,Cyber-Bullyiing detetction,"Cyberbullying, commonly defined as the electronic transmission of
insulting or embarrassing comments, photos, or videos",they don't specify what is type of bullying they are after,"1- Instgram sessions (2,218 , 
No.comments= 155,267)
2- Vine sessions (970, 
No comments = 78,250)","1- insta: 678 sessions (No. comments?)
2- vine: 304 sessions (No. comments?)","1- insta:  1540 sessions
 (No. comments?)
2- vine: 666 sessions (No. comments?)",1.0,0,0,0,0,LWIC model,"Netowork info and 
User information",0,0,"images meta data
Time","RF, SVM, LR",0,"1-using multimodlaity 
machien learnig
2- noise-resilient embedding refinement.
3-Xbully as feature","Raw Features (Raw): This is a concatenation of all the multimodal
features such as network feature and text feature.
• Bully [37]: A pretrained classifier4 based on textual analysis.
• SICD [6]: The state-of-the-art cyberbullying detection model
which use",0,0,0,0,0,0,0,"(RF)  Inst: 0.982 and Vine: 0.787
(SVM) Inst: 0.928 and Vine: 0.753
(LR) Inst: 0.878 and Vine: 0.804",WSDM 2019,0
90,Multilingual Cyberbullying Detection System,2018,Cyber-Bullyiing detetction,"the use of Internet, cell phones,
video game systems, or other technologies to send or post text
or images intended to hurt or embarrass another person or group
of people [5].",Cyberbullying,"Twitter_ar (35273)
Twitter_en (91431)",Twitter_ar (2196),0,0.0,handlabelled,0,TweetToSentiStrengthFeatureVector,0,0,0,0,0,SentiStrengthVector,NB,0,0,NB,0,0,0,0,0.93,0.94,0,0.92,CSNet'17 :,0
91,A Hierarchical Approach for Timely Cyberbullying Detection,2019,Cyber-Bullyiing detetction,"willful and repeated harm inflicted through the use of com-
puters, cell phones, and other electronic devices",aggressive ,Instagram (204 media sessions - 10000 messages),Instagram (1768 messages),Instagram (8230 messages),1.0,handlabelled,set misclassification cost,0remove punctuation and stop words,no 10 profane words,0,0,0,0,conditional feature probabilities,0,0,Hierarichal approach,"DRFS
DLR",0,0,0,0.737,0.65,0.4,0,0,IEEE,"To this end, we propose a novel
hierarchical approach that (i) first characterizes an individual mes-
sage as aggressive or not by evaluating the optimum least number of
informative features extracted from this message, and (ii) uses this
new knowledge to decide if it should continue reviewing messages
or conclude the process and raise a cyberbullying alert."
