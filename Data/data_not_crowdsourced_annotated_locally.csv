,Paper,year,category,Definition of Cyber-Bullyning,Type of Cyber-bullying,Dataset,Dataset positive sample,Dataset negative sample,Data Downlaoded,Data Collection process,Oversampleing pst instances,Preprocessing,Text Feature,Psycological features,User info features,Sentiment features,WE,Other features,ML model,Deel Learning model,Innovative model,baselines,Test set,Test positive ex.,Test negative ex.,Accuracy,Precision,Recall,AUC,F1,venue,Comments
4,Modeling the detection of textual cyberbullying,2011,Cyber-Bullyiing detetction,"when the internet, cell phones or other devices are used to send or post text or images intended to hurt or embaress another person","sexualty
race
intelligence
physical attributes",YouTube(50000),4500,45500,1.0,"data crawled from youtube abd annotated by 2 
middles school educators. 
The inter-rater agreement is kappa =0.4",0,1,"TF-IDF
Ortony lexicon words (negaative weight for profanity words)
POS unigrams
bigrams",0,0,0,0,0,"NB
Rule-Based
Decision tree
SVM",0,0,0,0,0,0,"sexuality - rule based (0/80)
Race - SVM (0.79)
Intelligence - SVM (0.77)",0,0,0,0,AAAI,0
7,Modeling the detection of textual cyberbullying.,2011,Cyber-Bullyiing detetction,"cyberbullying can be defined as the following: 'when the
Internet, cell phones or other devices are used to send or
post text or images intended to hurt or embarrass another
person’ ","sexuality, race, culture and intelligence","youtube vidoes on these senstive topics(50,000)",0,0,0.0,"2 annotators labelled the comments into 
race, sexuality, intelligence and none",0,0,"Tf-idf unigrams,
profanity words,
frequently POS bigrams,",0,0,Ortony lexicon with negative connotations,0,0,"NB, SVM, C4.5, rule based",0,0,0,"30% validation
20% test",0,0,"rule based :
(sexuality) 80.20%
(Race) 68.30%
intelligence(70.39%)",0,0,0,0,Association for the Advancement of Artificial Intelligence,Binary classififcation is better than multiclassififcation
11,Detecting Offensive Language in Social Media to Protect Adolescent Online Safety ,2012,cyber-Bullyiing detetction,they define offenisive  sentence as a sentence that contains strongly offensive words or weakly offensive words used to decribe anotehr person,offensive sentence,"Youtube(1700 sentence, 249 users)","sentences(610)
users (99)","sentences(1,090)
users(99)",0.0,"randomly crawled comments on 18 youtube videos
the users are labeled by 3 annotators with cohen kappa 0.73",0,1,"BOW
ngrams
NLP dependency detection",0,style,0,0,0,NB and SVM,0,0,0,handlabelled  sentences,173,0,0,"(LSF sentence IR)0.98
(LSF SVM user classification) 0.779","(LSF sentence IR)0.94
(LSF SVM user classification) 0.778",0,0,"International Conference on Privacy, Security, Risk and Trust and 2012 International Confernece on Social Computing",they use IR to find offensive entences and Classification ti find offensive users 
13,Improved cyberbullying detection using gender information,2012,cyber-Bullyiing detetction,an aggressive intentional act carried out by a group individual using electornic form of contact,harassment,"Msypace(381,000)",0,0,1.0,"Training (CAW2.0)
Test (hand labelled by 3 students)",0,0,"TF-idf of profane words
Tf-idf of personal pronoun",0,"gender
age",0,0,0,SVM,0,0,0,2200,0,0,0,0.43,0.16,0,0.23,Dutch-Belgian Information Retrieval Workshop,0
14,Towards User Modelling in the Combat against Cyberbullying ,2012,cyber-Bullyiing detetction,an aggressive intentional act carried out by a group individual using electornic form of contact,harassment,"Msypace(381,000)",0,0,1.0,"Training (CAW2.0)
Test (hand labelled by 3 students)",0,0,"TF-idf of profane words
Tf-idf of personal pronoun",0,"gender
age",0,0,0,SVM,0,0,0,2200,0,0,0,0.43,0.16,0,0.23,International Conference on Application of Natural Language to Information Systems,0
15,"Common sense reasoning for detection, prevention, and mitigation of cyberbullying",2012,Cyber-Bullyiing detetction,"when the internet, cell phones or other devices are used to send or post text or images intended to hurt or embaress another person","sexualty
race
intelligence
physical attributes",YouTube(50000),4500,45500,1.0,data crawled from youtube abd annotated by 2 middles school educators. The inter-rater agreement is kappa =0.4,0,1,"TF-IDF
Ortony lexicon words (negaative weight for profanity words)
POS unigrams
bigrams",0,0,0,0,0,"NB
Rule-Based
Decision tree
SVM",0,0,0,0,0,0,"sexuality - rule based (0/80)
Race - SVM (0.79)
Intelligence - SVM (0.77)",0,0,0,0,ACM Transactions on Interactive Intelligent Systems (TiiS),0
25,Expert knowledge for automatic detection of bullies in social networks,2013,Cyber-Bullyiing detetction,"Cyberbullying is defined as an aggressive, intentional
act carried out by a group or individual, using electronic forms of contact repeatedly
and over time against a victim who cannot easily defend him or herself",assigning bullying score to people,"youtube(54,050 comments from 3,603 usesrs)",12% of users are bullies,88%,1.0,"2 graduate studentns labeled the users as bullies or not 
with inter agreement Kappa of 0.78",0,0,"no profane words,
length of comment,
misspellings and short words,
comments targeted to someone
tf-idf",0,"hidden identities,
age of user,
period of membership,
no uploads,
no subscrptions,
no comments",no emotion icons,0,"A) Experts: a panel of 12 experts in the area of cyberbullying was asked to answer questions about the features presented in Table 1. For each feature they indicated 1) the
likelihood that a bully user belongs to a certain category relevant for that feature and
2) the importance of that feature. The likelihood was indicated on four-point scale
‘Unlikely’, ‘Less likely’, ‘Likely’ and ‘Very likely’ corresponding to values 0.125,0.375, 0.625 and 0.875 respectively
B)MCES decision making systems
","NB, SVM, C4.5, MCES",0,0,SVM (text features),0,0,0,MCES (0.76),0,0,0,0,anadian Conference on Artificial Intelligence,"2- We demonstrated that the expert system outperforms the machine
learning models and the hybrid approach results in a further but marginal improvement in prediction performance
1- compare three types of automatic detection: an expert system, supervised machine learning models, and a hybrid type combining the two."
26,Improving Cyberbullying Detection with User Context,2013,Cyber-Bullyiing detetction,an aggressive intentional act carried out by a group individual using electornic form of contact,0,Youtube(4626 comments and 3858 users) ,9.70%,90.30%,0.0,manually labelled with inter-annotation score 0.93,0,0,"no profane
first and sceonf person pronouns 
no cyberbullying words",0,"user history of using profane words
users linguistic style
age",no. emotion icons,0,0,SVM,0,0,0,0,0,0,0,0.77,0.55,0,0.64,European Conference on Information Retrieval,0
29,Experts and Machines against Bullies: A Hybrid Approach to Detect Cyberbullies ,2014,Cyber-Bullyiing detetction,"Cyberbullying is defined as an aggressive, intentional
act carried out by a group or individual, using electronic forms of contact repeatedly
and over time against a victim who cannot easily defend him or herself",assigning bullying score to people,"youtube(54,050 comments from 3,603 usesrs)",12% of users are bullies,88%,1.0,"2 graduate studentns labeled the users as bullies or not 
with inter agreement Kappa of 0.78",0,0,"no profane words,
length of comment,
misspellings and short words,
comments targeted to someone
tf-idf",0,"hidden identities,
age of user,
period of membership,
no uploads,
no subscrptions,
no comments",no emotion icons,0,"A) Experts: a panel of 12 experts in the area of cyberbullying was asked to answer questions about the features presented in Table 1. For each feature they indicated 1) the
likelihood that a bully user belongs to a certain category relevant for that feature and
2) the importance of that feature. The likelihood was indicated on four-point scale
‘Unlikely’, ‘Less likely’, ‘Likely’ and ‘Very likely’ corresponding to values 0.125,0.375, 0.625 and 0.875 respectively
B)MCES decision making systems
","NB, SVM, C4.5, MCES",0,0,SVM (text features),0,0,0,MCES (0.76),0,0,0,0,anadian Conference on Artificial Intelligence,"2- We demonstrated that the expert system outperforms the machine
learning models and the hybrid approach results in a further but marginal improvement in prediction performance
1- compare three types of automatic detection: an expert system, supervised machine learning models, and a hybrid type combining the two."
33,detecting online harassment in social networks,2014,online harassment,the process of sending messages over electronic media to casue psychological harm to a victim. If it persists then it is cyber bullying.,online harassment,"Twitter_general (5382)
Twitter_school (2793)
","Twitter_general (220 - 4%)
Twitter_school (194 - 7.4%)","Twitter_general (5162 - 96%)
Twitter_school (2599 - 92.6%)",0.0,Twitter API and annotated by 3 annotators. Twitter_school used school related keywords,0,"POS
noise (misspelling slang and abbreviations) removal
Twitter preprocessing",BOW,0,0,0,0,person identification - mark words or phrases that refer to a person using POS and usernames,NB,0,0,0,0,0,0,0,0.94,0.32,0,0.48,International Conference on Information Systems 2014,0
34,Cyber bullying detection using social and textual analysis,2014,Cyber-Bullyiing detetction,"the use of information technology to harm or harass other people in a deliberate, repeated and hostile manner",0,"Twitter(4865 meassges, 2150 conversations)",Twitter(91 – 1.8%),Twitter(4774 – 99%),0.0,labelled by 3 students,SMOTE method to mitigate the imbalance,0,"no. profane words
Ratio of uppercase letters
No exclamation marks
No smilies
POS
",0,"network features:no. Nodes
No edges
Degree of centerality
Edge between centrality
Links
Sharing score
",0,0,0,"J48,NB,SMO,Bagging and Dagging",0,0,0,30% of training,0,0,0,0,0,0.755,0,International Workshop on Socially-Aware Multimedia,0
37,Cyberbullying detection and prevention: data mining and psychological perspective,2014,Cyber-Bullyiing detetction,"bullying is targeting an individual or group of individuals and exposing them to 
ridicule and negative actions both physical and mental delibberately",0,Myspace,0,0,0.0,manually labelled,0,"Tokenizing
Filter out tokens based on length
stemming
silter stopwords",1,0,0,1,0,0,SVM,0,0,0,0,0,0,0,0,0,0,0,"International Conference on Circuits, Power and Computing Technologies",they use sentiment analysis and confidence as a metric
41,Collaborative detection of cyberbullying behavior in Twitter data,2015,Cyber-Bullyiing detetction,"use of information technoogy to harm or harass other people in 
a deliberate repeatedand hostile manner",0,"Twitter (340)
Twitter (1340)","Twitter (170)
Twitter (177)","Twitter (170)
Twitter (1163)",0.0,downloaded and labelled by them,0,0,"1gram
2gram
BOW",0,0,0,0,0,"NB
LR
SVM",0,multiclassification,0,0,0,0,0,0,0,0,0,international conference on electro/information technology (EIT),it is weired setup with hetrogenious nad homogenious classification
45,Identification and characterization of cyberbullying dynamics in an online social network,2015,Cyber-Bullyiing detetction,"is defined as using information technology to willfully and repeatedly hurt, insult or harass others.",0,MySpace (3032 post - 1129 users),MySpace (1915 post - 383 user),MySpace (1116 post - 744 user),0.0,labelled by 3 workers,0,0,"BOW
second person pronouns
offensive words",0,"age
gender
degree centerality
betweeness centerality
closness centerality
eigenvector centerality
clustering coefficient",1,0,0,DT,0,0,0,0,0,0,0.839,0,0,0,0.836,International Conference on Advances in Social Networks Analysis and Mining ,0
51,"Sustainable cyberbullying detection with category-maximized relevance of harmful 
phrases and double-filtered automatic optimization",2016,Cyber-Bullyiing detetction,"The National Crime Prevention Council in the USA, defines CBC as ‘‘when the Internet, cell phones or other devices are used to
send or post text or images intended to hurt or embarrass anothercperson’’","In addition, we categorized harmful words into three cate
gories:
obscene, violent and abusive. In this regard we followed
the definition provided by The Ministry of Education of Japan,
which specifically mentions words frequently used in cyberbullying
me",unofficial school website in Japan (2998),harmful (1490),unharmful(1508),0.0,"It contains 1490 harmful and 1508 non-harmful entries. The original data was provided by the Human Rights Research Institute Against All Forms for Discrimination and Racism in Mie Prefecture, Japan. manually labeled by expert annotators who are Internet P",0,0,0,0,0,0,0,0,0,0,"1- collecting seed words from the 3 categories of bullying
2-calculate a semantic orientation of harmfullness
3-maximize acquistion and filtering of seed word","[Study on the polarity classification model
for the purpose of detecting harmful information on informal school sites]
(in Japanese),","1- Testset2
2- 12% harmful 98% non harmful","1- 50%
2-12%","1-50%
2-98%",0,"1- for test set1 for 10 folds between 44% ro 80%
2-for testset2 between 10% to 60%","1- for test set1 between 5% to 100%
2- for test set2 between 13% to 100%",0,0,International Journal of Child-Computer Interaction,"1- after a year and half they found that the performance dropped by 30% because the seed words changed
2- To solve this, they proposed a method to automatically acquire and optimize seed words"
54,Cyberbullying detection based on semantic-enhanced marginalized denoising auto-encoder,2016,Cyber-Bullying detetction,"is an aggressive intentional actions performed by an individual or a group of people 
via digital communication methods such as sending messages and posting comments against a victim",0,"MySpace (1539)
Twitter (7321)","MySpace (398)
Twitter (2102)","MySpace (1141)
Twitter (5219)",1.0,"Twitter data was crawled using keywords, then manullay labelled
myspace data was labelled by 3 labellers",0,"tokenization
stemming
remove stop words
replace user mentions urls with predefined characters",unigrams and bigrams,0,0,0,0,0,0,smSDA,0,"Bullying word matching
semantic enhances BOW
LSA
LDA
mSDA","Twitter (6521)
MySpace (1139)",0,0,"Twitter (0.849)
MySpace (0.897)",0,0,0,"Twitter (0.0.719)
MySpace (0.776)",IEEE Transactions on Affective Computing journal,0
55,Automatic detection of cyberbullying on social networks based on bullying features,2016,Cyber-Bullying detetction,0,0,Twitter (1762),0,0,1.0,"Twitter data was crawled using keywords, then manullay labelled
myspace data was labelled by 3 labellers",0,"Tokenization
reterrs removed
urls usermentions and special characters are replaced by predefined characters",BOW,0,0,0,EBOW,0,SVM,0,0,"LSA
LDA
sBOW",0,0,0,0,0.76,0.794,0,0.78,international conference on distributed computing and networking,0
64,"Automatic detection of cyberbullying in social
media text",2017,0,a content taht is published online by an individual and that is aggressive or hurtful against a victim,"threat
insult
exclusion
sexual talk
defense
encouragment to harassment","Askfm - Englsih (113698)
Askfm - Ducth (78387)",0,0,1.0,"data annotated by experts (linguists) with
 interannotator agreement score (Cohen kappa - Ducth) 
is 0.69 and (Fleiss kappa - English) is 0.59",cost-senstive,"POS
lemmatisation
","word n-grams
char n-gram
BOW
Term lists",0,0,1,0,Topic modelling (LDA nad LSI),SVM,0,0,0,0,0,0,0,"English (0.74)
Dutch (0.67)",English (0.56) Dutch (0.52),"AUCROC
English (0.77) Dutch (0.75)
",English (0.64) Dutch (0.58),PLOS ONE journal,they comapre the performance of different combinations of features and the performance to detect different types of cyberbullying
69,"Cyberbullying Intervention Interface Based on Convolutional
Neural Networks",2018,Cyber-Bullyiing detetction,"Cyberbullying, which can be defined as ‘when the Internet, cell phones or other devices are
used to send or post text or images intended to hurt or embarrass another person’ (Dinakar
et al., 2012),","bullying
anxiety
 depression.","The data was collected by the Visr child safety app from September 2014 to March 2016.
Over a half-million online posts were selected from among the social media platforms (Face
book,
Instagram, Twitter, Pinterest, Tumblr, Youtube) and Gmail. (total = 14,",1753 (12.3%),12441 (87.7%),0.0,anntated by 3 workers with Cphen's kappa = 0.805,0,0,"BOW word unigrams

As suggested by previous research, we also added textual features (total used:
4
93) from LIWC 2015",0,0,0,0,0,0,CNN,0,"SVM
ZeroR",0,30% in total,30% in total,0,0,0,0.898,0,ACLweb 2018,0
70,Detecting Hate Speech on Twitter Using a Convolution-GRU Based Deep Neural Network,2018,Hate speech detetction,"we identify that hate speech
(1) targets individual or groups on the basis of their characteristics (targeting
characteristics); (2) demonstrates a clear intention to incite harm, or to promote
hatred; (3) may or may not use offensive or profane words.","hatespeech
refugees","Twitter (2,435)",414 (17%),2021 (83%),0.0,"annotated by liguistic researcher and 2 student researchers 
(agreement score not given)","filtering twitter api using keywords
 and hashtags in 3 batches",0,"(Unigrams,bigrams and trigrams )Tfidf
number of mentions, and hashtags4; 
number of characters, and words;",0,0,"sentiment polarity 
scores of the tweet",0,"1-Linguistic features like POS
2-Enhanced feature set",0,CNN + GRU,0,"SVM, CNN",0,0,0,0,0,0,0,0.92,Nature 2018,"it sets new benchmark by outperforming on 6 out of 7 datasets by between
1 and 13% in F1. We also extend the existing dataset collection on this
task by creating a new dataset covering different topics."
72,Using Fuzzy Fingerprints for Cyberbullying Detection in Social Networks,2018,Cyber-Bullyiing detetction,"As a phenomenon, cyberbullying is defined as an
individual’s intentional, deliberate and repeated acts of cruelty
to others through harmful posts, messages, or other forms
of social aggression through various digital technologies [2].",0,Formspring (13160),2205 (16.7%),10955 (83.24%),1.0,anntated by 3 workers with no agreement score provided,"1- no-cyberbullying data down sampled
2-balanced dataset
3-full original dataset",0,"TF-IDF
",0,0,0,0,0,Fuzzy Finger Print,0,"Fuzzy Finger Print ti identify the unqiue
 finger pront of cyber bullying class (kwyowrds)","SVM,
MNV 
LR",0,0,0,0,0,0,0,"balanced ds 0.810 (not the best)
unbalanced ds 0.773 (not the best)
balanced training _unbalanced_test 0.390 
(not the best)",IEEE international conference 2018,"1- Experiments show that
the Fuzzy Fingerprints slightly outperforms baseline classifiers
when tested in a close to real life scenario, where cyberbullying
instances are rarer than those without cyberbullying.
2-cyberbullying detection is not a binary tas"
76,Optimal Online Cyberbullying Detection,2018,optimizing scalability and timliness of cyberbullying detection ,0,Cyberbullying,Twitter(10600),Twitter(5300),Twitter(5300),0.0,manually labelled,0,0,"no acronyms
offensive acronyms",0,0,mean value of valence or arousal or dominance,0,0,0,0,AvOID algorithm for optimal online cyberbullying detection,0,0,0,0,0,0,0,0,0,ICASSP,They dont report experiement results. they report probability of error.
78,Cyberbullying Detection on Instagram with Optimal Online Feature Selection,2018,optimizing scalability and timliness of cyberbullying detection ,"repetitive hostile behaviour using digital media (e.g. hurtful comments- videos-images) 
in an effort to intentionally and repeatedly harass or harm individuals",Cyberbullying,Instagram (2218 media sessions),Instagram (20%),instgram (80%),1.0,manualy labelled,create smaller datasets with less imbalanced ratio,0,"no profane words
unigrams",0,"no followers
no followees
no shared media",0,0,0,CONcISE,0,"DRFS
RF-Multi
PVC",0,0,0,0,0.8113,0.76,0.77,0.87,0.76,IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining (ASONAM),"we propose
a novel algorithm to drastically reduce the number of features
used in classification. We demonstrate the utility, scalability and
responsiveness of our approach using a real-world dataset from
Instagram, the online social media platform with the highest
percentage of users reporting experiencing cyberbullying. Our
approach improves recall by a staggering 700%, while at t"
79,A Socio-linguistic Model for Cyberbullying Detection,2018,Cyberbullying  and bullies,0,Cyberbullying,Twitter (1798),Twitter (27%),Twitter (73%),0.0,annotated by 3 annotators with Fleiss agreement score of 0.14,0,"remove stopwords 
remove numbers
remove nonenglish words
trimming repeated characters
","Ngram
Ngram++
seed++
latent linguistic",0,sociolinguistic,0,Glove ad Doc2vec,PSL,SVM,0,0,0,0,0,0,0,"cyberbullying(0.48)
bullies(0.61)","cyberbullying(0.70)
bullies(0.0.70)",0,"cyberbullying(0.56)
bullies(0.73)","IEEE/ACM ASONAM 2018, August 28-31, 2018","They use PLS and SVM to detect cyberbulling and bullies
"
81,NLP and Machine Learning Techniques for Detecting Insulting Comments on Social Networking Platforms,2018,Cyber-Bullyiing detetction,0,Cyberbullying,"Kaggle (2235)
Twitter (6000)",0,0,0.0,data manually labelled,0,"tokenization
stemming
remove unicode characters
remove stopwords","Tf-idf
no profanty words
no seconf person pronoun
4grams and 5grams",0,0,0,0,0,"LR
SVM
RF
GBM",0,0,0,Kaggle,0,0,RF (0.766),0,0,RF(0.579),0,2018 International Conference on Advances in Computing and Communication Engineering,0
83,Understanding Cyberbullying on Instagram and Ask.fm via Social Role Detection,2019,Cyber-Bullyiing detetction,0,aggressive,"Instgram (13,350 comment)
",12%,88%,0.0,"The labeled Instagram
comments are chosen from top 200 media sessions ranked
by the number of insulting words which appeared in the comments
of the media session, the percentage of negative comments, and the
absolute number of negative comments on the med",0,0,"73 features from LIWC2015 categories [15], the compound sentiment
score from VADER [10], and 7 basic linguistic features (e.g.,
the number of upper case words)",1,0,1,0,0,RF,0,0,0,0,0,0,0,0.4,0.35,0,0.37,www 2019,"In this work, we focus our analysis on three different social roles
in cyberbullying: victim, bully, and supporter. Figure 2 describes
the pipeline of our social role detection method. Social roles are
identified based on the aggressive label of comments "
87, ,2019,bullies detetction,"describes the use of electronic forms of communi-
cation to intentionally harm or harass others",cyberbullying,"Twitter (3095)
Twitter (19994)","Twitter (1794)
Twitter (3845)","Twitter (1301)
Twitter (16149)",0.0,one dataset borrowed and another labelled by 3 experts,0,0,0,LWIC model,0,0,0,0,0,0,PI-bully,"KNN
RF
SVM
Bully
SICD",0,0,0,0,0.425,0.887,0.844,0.574,0,"n this paper,
we propose a personalized cyberbullying detection
framework, PI-Bully, that draws on empirical find-
ings from psychology highlighting unique charac-
teristics of victims and bullies and peer influence
from like-minded users as predictors of cyberbully-
ing behaviors. Our framework is novel in its ability
to model peer influence in a collaborative environ-
ment and tailor cyberbullying prediction for each
individual user"
90,Multilingual Cyberbullying Detection System,2018,Cyber-Bullyiing detetction,"the use of Internet, cell phones,
video game systems, or other technologies to send or post text
or images intended to hurt or embarrass another person or group
of people [5].",Cyberbullying,"Twitter_ar (35273)
Twitter_en (91431)",Twitter_ar (2196),0,0.0,handlabelled,0,TweetToSentiStrengthFeatureVector,0,0,0,0,0,SentiStrengthVector,NB,0,0,NB,0,0,0,0,0.93,0.94,0,0.92,CSNet'17 :,0
91,A Hierarchical Approach for Timely Cyberbullying Detection,2019,Cyber-Bullyiing detetction,"willful and repeated harm inflicted through the use of com-
puters, cell phones, and other electronic devices",aggressive ,Instagram (204 media sessions - 10000 messages),Instagram (1768 messages),Instagram (8230 messages),1.0,handlabelled,set misclassification cost,0remove punctuation and stop words,no 10 profane words,0,0,0,0,conditional feature probabilities,0,0,Hierarichal approach,"DRFS
DLR",0,0,0,0.737,0.65,0.4,0,0,IEEE,"To this end, we propose a novel
hierarchical approach that (i) first characterizes an individual mes-
sage as aggressive or not by evaluating the optimum least number of
informative features extracted from this message, and (ii) uses this
new knowledge to decide if it should continue reviewing messages
or conclude the process and raise a cyberbullying alert."
